{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Text Classification**\n",
        "By Hamna Mustafa - hbm170002\n"
      ],
      "metadata": {
        "id": "nz3VywvCpli0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWZRPReK4P7-"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import pandas as pd\n",
        "import seaborn as sb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "I got the following dataset from Kaggle: https://www.kaggle.com/datasets/jonathanbesomi/superheroes-nlp-dataset\n"
      ],
      "metadata": {
        "id": "7ovLcUy1p5SO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reading in my dataset \n",
        "df = pd.read_csv('/content/superheroes_nlp_dataset.csv')\n",
        "print('rows and columns:', df.shape)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emL47a3S4Um3",
        "outputId": "9ea53c05-fc51-4a0c-85ad-6eba0004a73e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rows and columns: (1450, 81)\n",
            "            name               real_name               full_name  \\\n",
            "0        3-D Man     Delroy Garrett, Jr.     Delroy Garrett, Jr.   \n",
            "1  514A (Gotham)             Bruce Wayne                     NaN   \n",
            "2         A-Bomb  Richard Milhouse Jones  Richard Milhouse Jones   \n",
            "3             Aa                      Aa                     NaN   \n",
            "4     Aaron Cash              Aaron Cash              Aaron Cash   \n",
            "\n",
            "  overall_score                                       history_text  \\\n",
            "0             6  Delroy Garrett, Jr. grew up to become a track ...   \n",
            "1            10  He was one of the many prisoners of Indian Hil...   \n",
            "2            20   Richard \"Rick\" Jones was orphaned at a young ...   \n",
            "3            12  Aa is one of the more passive members of the P...   \n",
            "4             5  Aaron Cash is the head of security at Arkham A...   \n",
            "\n",
            "                                         powers_text  intelligence_score  \\\n",
            "0                                                NaN                  85   \n",
            "1                                                NaN                 100   \n",
            "2    On rare occasions, and through unusual circu...                  80   \n",
            "3                                                NaN                  80   \n",
            "4                                                NaN                  80   \n",
            "\n",
            "   strength_score  speed_score  durability_score  ...  has_flight  \\\n",
            "0              30           60                60  ...         0.0   \n",
            "1              20           30                50  ...         0.0   \n",
            "2             100           80               100  ...         0.0   \n",
            "3              50           55                45  ...         0.0   \n",
            "4              10           25                40  ...         0.0   \n",
            "\n",
            "   has_accelerated_healing has_weapons_master has_intelligence has_reflexes  \\\n",
            "0                      0.0                0.0              0.0          0.0   \n",
            "1                      0.0                0.0              0.0          1.0   \n",
            "2                      1.0                0.0              0.0          1.0   \n",
            "3                      0.0                0.0              0.0          0.0   \n",
            "4                      0.0                1.0              0.0          0.0   \n",
            "\n",
            "  has_super_speed has_durability has_stamina has_agility has_super_strength  \n",
            "0             1.0            0.0         0.0         0.0                1.0  \n",
            "1             0.0            1.0         0.0         0.0                1.0  \n",
            "2             1.0            1.0         1.0         1.0                1.0  \n",
            "3             0.0            0.0         0.0         0.0                0.0  \n",
            "4             0.0            0.0         0.0         0.0                0.0  \n",
            "\n",
            "[5 rows x 81 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the shape of this dataset, we can see that there are many columns that are not text-based. This dataset can be used for many different NLP projects. However, for our text classification project, only 3 columns will be considered: creator, powers_text, and history_text\n",
        "\n",
        "I will attempt to train a model that can guess the creator of the 'superhero' based on the powers_text and history_text column. \n",
        "\n",
        "Below, I am checking how many rows in the creator column are empty. "
      ],
      "metadata": {
        "id": "XgQ-3lqsqK21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checking how many rows in the creator column are null\n",
        "df.isnull().sum()['creator']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RA2OY5eU6wZb",
        "outputId": "7bc228d4-40d2-47cd-ad20-8cec8ff6e333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "139"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am only keeping the 3 columns mentioned above in my data frame and deleting all the rows in which creator is null."
      ],
      "metadata": {
        "id": "LubzgghRq6oe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[[\"history_text\", \"powers_text\",'creator']]\n",
        "df = df.dropna(subset=['creator'])\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4njKvmr97zjJ",
        "outputId": "827e9fa1-3fdb-4897-bac5-2e96b4563049"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "history_text     78\n",
              "powers_text     346\n",
              "creator           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, the powers_text column had way too many NA's. If I deleted all these rows, my dataframe would be become quite small. Thus, I decided to delete the powers_text column and train my model to predict the creator based on just the history-text column."
      ],
      "metadata": {
        "id": "I34RnqzxrGv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# only keeping two columns\n",
        "df = df[['history_text','creator']]\n",
        "\n",
        "# deleting all rows where the history_text is empty\n",
        "df = df.dropna(subset=['history_text'])\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmtFWG5IHT1Y",
        "outputId": "854326f5-6f48-4349-cf7c-407fb854b94a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "history_text    0\n",
              "creator         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting a graph showing a distribution of the target classes."
      ],
      "metadata": {
        "id": "ujVyk1-Vroyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sb.catplot(x='creator', kind='count', data=df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "er2t3JQp85XU",
        "outputId": "1863e7dc-ccf3-4fed-c918-8310a4d4abf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7fe7d0cb36a0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFgCAYAAABqo8hyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debglVXnv8e/b3YwiMrWAgMFEoiGJIOk4kJh44SYyqM0kMY/KIKFDAlGixpDhGmKuiUmMBMTgRVEhaqJMgsglcBGMiaI2isxKgxC6w3CYoZue3/vHWuUuztCcHnavQ/f38zzn2XuvmlZVrfrV2lV77xOZiSSpjWmtKyBJGzNDWJIaMoQlqSFDWJIaMoQlqaEZrSuwNg444IC84oorWldD0tQXrSswked0T/ihhx5qXQVJWivP6RCWpOe6oYZwRGwTERdExO0RcVtEvDYitouIqyLijvq4bR03IuKMiJgXETdGxD7DrJskTQXD7gmfDlyRmS8H9gJuA04Brs7MPYCr62uAA4E96t8c4Kwh102SmhtaCEfEC4BfA84ByMylmfkYMBs4t452LnBIfT4bOC+L64BtImLnYdVPkqaCYfaEXwKMAJ+JiO9HxKci4nnAjpl5Xx3nfmDH+nwX4N7e9PNrmSRtsIYZwjOAfYCzMvOVwEIGlx4AyPLrQav1C0IRMSci5kbE3JGRkXVWWUlqYZghPB+Yn5nfrq8voITyA91lhvr4YB2+ANitN/2utewZMvPszJyVmbNmzpw5tMpL0vowtBDOzPuBeyPiZbVof+BW4FLg6Fp2NHBJfX4pcFT9lMRrgMd7ly0kaYM07G/M/QHw+YjYFLgLOJYS/F+KiOOAe4Aj67iXAwcB84BFdVxJ2qANNYQz8wZg1jiD9h9n3AROHGZ9JGmq8RtzktSQISxJDRnCktTQc/qnLAFGzvrcmLKZv/f2BjWRpNVnT1iSGjKEJakhQ1iSGjKEJakhQ1iSGjKEJakhQ1iSGjKEJakhQ1iSGjKEJakhQ1iSGjKEJakhQ1iSGjKEJakhQ1iSGjKEJakhQ1iSGjKEJakhQ1iSGjKEJakhQ1iSGjKEJakhQ1iSGjKEJakhQ1iSGjKEJakhQ1iSGjKEJakhQ1iSGjKEJakhQ1iSGjKEJakhQ1iSGjKEJakhQ1iSGjKEJakhQ1iSGjKEJamhoYZwRNwdETdFxA0RMbeWbRcRV0XEHfVx21oeEXFGRMyLiBsjYp9h1k2SpoL10RP+H5m5d2bOqq9PAa7OzD2Aq+trgAOBPerfHOCs9VA3SWqqxeWI2cC59fm5wCG98vOyuA7YJiJ2blA/SVpvhh3CCVwZEddHxJxatmNm3lef3w/sWJ/vAtzbm3Z+LXuGiJgTEXMjYu7IyMiw6i1J68WMIc//VzNzQUS8ELgqIm7vD8zMjIhcnRlm5tnA2QCzZs1arWklaaoZak84MxfUxweBi4FXAQ90lxnq44N19AXAbr3Jd61lkrTBGloIR8TzIuL53XPgN4GbgUuBo+toRwOX1OeXAkfVT0m8Bni8d9lCkjZIw7wcsSNwcUR0y/lCZl4REd8FvhQRxwH3AEfW8S8HDgLmAYuAY4dYN0maEoYWwpl5F7DXOOUPA/uPU57AicOqjyRNRX5jTpIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIamtG6AsMy8olPjCmbecIJDWoiSROzJyxJDRnCktSQISxJDQ09hCNiekR8PyIuq69fEhHfjoh5EfHFiNi0lm9WX8+rw3cfdt0kqbX10RN+N3Bb7/XfAqdl5kuBR4HjavlxwKO1/LQ6niRt0IYawhGxK3Aw8Kn6OoD9gAvqKOcCh9Tns+tr6vD96/iStMEadk/4H4H3Ayvr6+2BxzJzeX09H9ilPt8FuBegDn+8jv8METEnIuZGxNyRkZFh1l2Shm5oIRwRbwQezMzr1+V8M/PszJyVmbNmzpy5LmctSevdML+s8SvAmyPiIGBzYGvgdGCbiJhRe7u7Agvq+AuA3YD5ETEDeAHw8BDrJ0nNDa0nnJl/kpm7ZubuwFuBr2Xm24BrgCPqaEcDl9Tnl9bX1OFfy8wcVv0kaSpo8TnhPwbeExHzKNd8z6nl5wDb1/L3AKc0qJskrVfr5bcjMvNa4Nr6/C7gVeOMsxh4y/qojyRNFX5jTpIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqaFJhXBEXD2ZMknS6pmxqoERsTmwJbBDRGwLRB20NbDLkOsmSRu8VYYw8LvAycCLgOsZhPATwJlDrJckbRRWGcKZeTpwekT8QWZ+bD3VSZI2Gs/WEwYgMz8WEfsCu/enyczzhlQvSdooTCqEI+KfgZ8BbgBW1OIEDGFJWguTCmFgFrBnZuYwKyNJG5vJfk74ZmCnYVZEkjZGk+0J7wDcGhHfAZZ0hZn55qHUSpI2EpMN4VOHWQlJ2lhN9tMRXx92RSRpYzTZry0/GRFP1L/FEbEiIp54lmk2j4jvRMQPIuKWiPjLWv6SiPh2RMyLiC9GxKa1fLP6el4dvvvarpwkTXWTCuHMfH5mbp2ZWwNbAIcD//Qsky0B9svMvYC9gQMi4jXA3wKnZeZLgUeB4+r4xwGP1vLT6niStEFb7V9Ry+LLwBsmMd5T9eUm9S+B/YALavm5wCH1+ez6mjp8/4joviYtSRukyX5Z47Dey2mUzw0vnsR00ym/OfFS4OPAncBjmbm8jjKfwQ8B7QLcC5CZyyPicWB74KFR85wDzAF48YtfPJnqS9KUNdlPR7yp93w5cDel57pKmbkC2DsitgEuBl6+uhUcZ55nA2cDzJo1yy+PSHpOm+ynI45dm4Vk5mMRcQ3wWmCbiJhRe8O7AgvqaAuA3YD5ETEDeAHw8NosV5Kmusl+OmLXiLg4Ih6sfxdGxK7PMs3M2gMmIrYAfgO4DbgGOKKOdjRwSX1+aX1NHf41vyYtaUM32Rtzn6GE5Ivq31dq2arsDFwTETcC3wWuyszLgD8G3hMR8yjXfM+p458DbF/L3wOcsjorIknPRZO9JjwzM/uh+9mIOHlVE2TmjcArxym/C3jVOOWLgbdMsj6StEGYbE/44Yh4e0RMr39vx+u1krTWJhvC7wSOBO4H7qNcsz1mSHWSpI3GZC9HfBA4OjMfBYiI7YCPUMJZkrSGJtsTfkUXwACZ+QjjXO+VJK2eyYbwtPov74Gf9IQn24uWJE1gskH6D8C3IuL8+votwIeGUyVJ2nhM9htz50XEXMqP7wAclpm3Dq9akrRxmPQlhRq6Bq8krUOr/VOWkqR1xxCWpIYMYUlqyBCWpIYMYUlqyBCWpIYMYUlqyBCWpIYMYUlqyBCWpIYMYUlqyBCWpIYMYUlqyBCWpIYMYUlqyBCWpIYMYUlqyBCWpIYMYUlqyBCWpIYMYUlqyBCWpIYMYUlqyBCWpIYMYUlqyBCWpIYMYUlqyBCWpIYMYUlqyBCWpIYMYUlqyBCWpIYMYUlqaGghHBG7RcQ1EXFrRNwSEe+u5dtFxFURcUd93LaWR0ScERHzIuLGiNhnWHWTpKlimD3h5cB7M3NP4DXAiRGxJ3AKcHVm7gFcXV8DHAjsUf/mAGcNsW6SNCUMLYQz877M/F59/iRwG7ALMBs4t452LnBIfT4bOC+L64BtImLnYdVPkqaC9XJNOCJ2B14JfBvYMTPvq4PuB3asz3cB7u1NNr+WjZ7XnIiYGxFzR0ZGhlZnSVofhh7CEbEVcCFwcmY+0R+WmQnk6swvM8/OzFmZOWvmzJnrsKaStP4NNYQjYhNKAH8+My+qxQ90lxnq44O1fAGwW2/yXWuZJG2whvnpiADOAW7LzI/2Bl0KHF2fHw1c0is/qn5K4jXA473LFpK0QZoxxHn/CvAO4KaIuKGW/SnwYeBLEXEccA9wZB12OXAQMA9YBBw7xLpJ0pQwtBDOzP8AYoLB+48zfgInDqs+kjQV+Y05SWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWpoaCEcEZ+OiAcj4uZe2XYRcVVE3FEft63lERFnRMS8iLgxIvYZVr0kaSoZZk/4s8ABo8pOAa7OzD2Aq+trgAOBPerfHOCsIdZLkqaMoYVwZv478Mio4tnAufX5ucAhvfLzsrgO2CYidh5W3SRpqljf14R3zMz76vP7gR3r812Ae3vjza9lkrRBa3ZjLjMTyNWdLiLmRMTciJg7MjIyhJpJ0vqzvkP4ge4yQ318sJYvAHbrjbdrLRsjM8/OzFmZOWvmzJlDrawkDdv6DuFLgaPr86OBS3rlR9VPSbwGeLx32UKSNlgzhjXjiPgX4PXADhExH/gL4MPAlyLiOOAe4Mg6+uXAQcA8YBFw7LDqJUlTydBCODN/e4JB+48zbgInDqsukjRV+Y05SWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWpoRusKSJN18IWfHFP21cOPb1ATad2xJyxJDRnCktSQISxJDRnCktSQN+Z6Fpx5wpiyXU76RIOaSNpY2BOWpIbsCa+l6z/xpjFlv3TCVxrURNJzkT1hSWpoo+wJ33/Wh8aU7fR7f9agJpI2dhtlCD8Xfe6zbxhT9vZj/g2AT543dtjxR/3b0Oskae15OUKSGjKEJakhL0c0cMU5B40pO+C4yxvURFJrhvAQ/fsnDx5T9mvHf3WV01z0mQPGlB127BVrtPzTPz/2WvG73+a14vXtLRfeNKbs/MN/sUFNNBVNqRCOiAOA04HpwKcy88ONq7TRee8FY08C/3DEmp0EVuXgi/9+TNlXD/2jdb6cN17wr2PKLjviret8OdKamjIhHBHTgY8DvwHMB74bEZdm5q1ta7Zh+tAXx/aS/+y3nru95DdecN6YssuOOGqV07zpgovHlH3liEOZfcHYS0OXHDH2EtIw/e+L7xtT9ueH7rzelv+DTz44pmyv41+4xvO7/6O3jSnb6T0/t8bz25BMmRAGXgXMy8y7ACLiX4HZwJQI4R9+fPaYspedeEmDmrRz+CVje8kXzr6CAy/5/THl/3f2PwFw0MUfGDPs8kM/uMrlHHzRmWPKvnrYSZOt5lAdcsHXxpR9+Yj9OOzCb40pv+jw165yXkdddM+YsvMO+6lVTvPJi8aG4/GHlXC88IKHxgw7/IgduPJfxpb/5m/vAMA3zxsZM2zfo2ausg53nXH/mLKfftdO3Pd39447/s7v323CeT3wj3PHLd/x5Fk8cMY3xpa/63U8eOb4nYUXnvQGHvz4l8eWn3jIhMufCiIzW9cBgIg4AjggM3+nvn4H8OrMPGnUeHOAOfXly4Af1uc7AGNb26qHOY3TOM3GMc1DmTm2FzEVZOaU+AOOoFwH7l6/AzhzNaafu7rDnMZpnGbjm2aq/U2lzwkvAPrvW3atZZK0wZpKIfxdYI+IeElEbAq8Fbi0cZ0kaaimzI25zFweEScB/0b5iNqnM/OW1ZjF2WswzGmcxmk2vmmmlClzY06SNkZT6XKEJG10DGFJamltPloBJPC53usZtexx4Af1+Y+AWyhfuriPEvyzgE8CK4ElwNPAQuAzwLTe/F4FfLuO833gU8CWwO7Azb3xZtfpf1iXcy/wCOWbd7cAp45T91Mpn754sD7eAGxDuSa9AnhfXd4y4APAN4A7gUfrei2ry1kELKVcg3qsrssKYHld/lnAH9ZxF9Rtswy4GfgWcGCvTsuAPYHta31uqONnff5onfcXan22BI4BnqjrcUMd9z7ge938gRcBFwA/C1wOPFy3fdbHFcADvfW6oW7L/1fnPQ8YAZ6q2/XxuozFdT1XAif11uP1wGW954vrvJ8GngT+qE7zWJ33jyif6dy9jndpb15XUm7afgM4AzikjrOibsPHah2y1vW2un631Xl323tR3UYPAHfV8b9X12Mppd08DtxRny8EfgX4+zr/JZT9v6jW60V1+UlpYzfU5S4B7q/r2W3fbrsuAD4HvGiC4+mYup0fq9N8BjgT+GBdt9+v672o1nUJpV39B3Bjt069+b0PuLaWZ13PrzE4TlfWbfF03UeP1P1+TJ0+6n7Zttbty3W6X+0t4+FR+yvrdlnCoO0+BVzWLbM37ofqdnma0rb/GNi37vMf1/23FPg94CDgm7029YfAd4Db6/yvBBaOsz3PBE4AjgLupnx+eG/goDXIu1nAGVPtI2oLgV+IiC3q69+g7NhvZOZelB17X2b+POVzv88H/gK4HviFuoGfl5lbAK8DXluHExE7AucDHwbuyMxXAlfUefxEHe/jlIa/F7AJpaGfA/wj5QDeaoL6n0Zp2P9J2cBPUHZSAGT54sg0yg6eAexC+W2LpDS+L1Aa7gzgTXV7fJsSdN8H/hL4RUrjmg5sRmnIf0sJyEOAF/TqsyQzb83MhzNz71qn0+p2OqAu8+lan70oIdz5Qt0+y4HnAa+u839+Zv438Hbgq5SDclNKAz4V+DXg/cDmlAP8oczcOzNfVrcjwGsycyYwl3Kw3ENp0C+mBNty4KIJtvGetc4L637+NPDLdRt/vS7j7MzcoTfNqyOiex318YnMfBfw25TQWUEJulMoB/j9lDY0B/jTun6/QwlHgP3qum5GaaPLgRPrsEsoIf/3wK9n5p6UfboP8GZKG3hn3abdTZSfYhC0v07Z11tTgntZnSYzcxqlXbyWcmL4VeBFUUwDiIj+DfIvUk5+CRwObJGZH6C0sy/VbfkDSpvajRKaSyknjyXAtr1t11la1/kRStvpvoO9nBJ2d2bm5sB7KO335Ig4NkvyXFfXaRrw05STxL4RMS0iXgaMZOabe8taCMyknNyuoWTAlpQ2t7isbmwREX8OvLGuz52UNnU4Zf/uT2kXn6Ds1+0ooblvXcaRlH18dGa+nNIur2DQVvoiMz8BfL5XtndvG0xaZs6tbXDdWsue8FPAXwNH1NfnURpC1wtaQtnx36cE748ZhNdSSkNbXv8WUEJwEYPeZHe2Xk45u95JaeBL699vUULxSQZn1CeBP6fs8GX1settP17rvKSWr6jlXQNdxtgeYlKCvOtNdGXLe+Ouzt/y3jyyt6ynR82/PywnWFZX7/GW8WhvmyytZcvGmX9SwnCiuq7sbZeVo5Z9Xx2W4wzv/hb3xuken5hgnR6boHxhrfd426Zf9vQ4y++Wu3ic8g+Os42XMGibK0bNoytfSDkJPdtyk9LmVo6aX3/9xluv0W1tVWUTTTvR/hhvfqPHm2ieq6rLYkqvevQ2696pjIyq27O1m2Rw8ugfM8t7062g5MbSUfNYTOkc9Ld11/4foLS/rg53U7LpKspHYm+tdf1vSub8CHjdOO/wTqV0KK6t6/2uXi7+L8rJ8T+AfwHeN8yeMMC/Am+NiM2BV1B6EK+LiNspZ78Dai/2o5Qz2nRKj3IapXc0A3gX5Wx5d904m9cVO48SJsspvbVdgZsovQooPZdXUHq6MygBvohy+SAoZ8in67CbGITTHbVsZX0Myk7rGgqUHkn3tcfnM9ihD9Sym+p0i+rrrrGs7L2GwVv2ztL6uKI+/helt7FZff0jxrd8nLIVlLeKSelldQ16EWV7rqRcYrmZst3/utYHSgO8vT7fp1ffbv1X1mmoj8vq+s6vZQHsxOCt7ZOUk+xKBqG/vJbP6M2nvy7LeuNlb7yo69Z9RPGBOk7X0/l0b7yDenVfUecJ5SD6z966dOMsovSuoPTwuvn8sD7OoPfWmdIGukA4uNZjS0qb6Pbl5pRg7p9guu3Yta87KZfgoLTJ6xl4B4NQe6i3DssZBAyUyyfT6riX1bKR3nAoJ8YudKLWZ7Ru/CU8c7s+waAXT28d7qK8s6DWr1vv5QwuY3Udo2mUY2NRne9mdbwdevMLysmpW+b9ddh8SqcKyjZaUut6C4Nj8d46bDnlEtuTlHZ1ZR2+jJI7/11fX03peD3Rq980ymWZO4B7MvOXah1+tr4LupvSto8BTqa+Ox/Hy4E3UC6b/kVEbBIRv0zp0e9FuRQ4a4JpB9a2J1wf5wLHUg7ypxmcLZ6uK38z5YBfQjkzfp1B7/UmSu8463jd9aknKY2y6310O3mEcrZaSblccX2d51OUoL+IEmpfppwlz6vTfbsup1tuN++76rzeSjkQu0D4OoOz6WIGZ9T+QTZRD6SbpjsY+mfp5eNM82RvvrcwOPAeH2e+3fjddc6l4wzvXi+nXCvs5v2B3vhLeGav5Z5VzGeEZ75L6K9Hv3e3pDfOit60T9Wya+vj7b3HhxgEWL8+i3rl9zHxO5CVo6bpv+56W4t7+7Bfx8UMThiP1fJHGVxmeJDSJhcztrc7n8E14UW95XX17N7NdXVYWpfdredpvXqMMHa7d23txxOsaxe23xhV3nVautdP9Z4vGTWfpydYbv+vW5+uDS2kHLPd/Lp6LKvL6rZhN+0ySo+w23cTvZtZVufVn3e3z55i0G4fZtC2buotqztmuvE+Nqq8q+PTlID+Qt3PSxjce/luza1rKVkwC9iR8sNiMLYn/Ge9LLyN0kk8GfjLXvlHWQ89YSjd+I9Qut59Xc9mP8r1uWkM3kJsXjfMKxncUNqJclbrbqI8XKe7g9JDfIRyLeggyg6dTtmgweCMOfFPNhV3UQ78Jyhn8fPqtPtSGljXC9kX6K51/4hBg/lSLeuCpDu7d72tLnyf6pV340AJOxhcCrmzbqfuuvUWDHpPXW8dSg+AOq/LGfQmp9dx+j0rKNvulMx8BYPw26s3vzuBP+nVbdv62L3t7n57sN+b7XpMDzPoLXXXyB6tZVHXvbuEA4Oe05W17Kfr6xdSwq8Lh66XvpJyDa/bF92B261/Vw7lBk0XOt9h8CH97NW364F3B2F3cG9Wn49QbhZ2Af1bdfyt67puUsftLl8s55mfLPomg/a4qD5/ui6/e2fTbZdOdyONOk4/rLv1u49yTMAz9wmUkOkuCfVNp1wz7trdZr1hjzFWvxd9da03vbp2J73He+M9Uh83Af5PrdtCBvcoPkfZDtMo2+/uWt61j+6n4LqOwlN1PWZQ2mUyuLSxuE7XtY331emXUdrcVnX8z9bxR+rjL9Txb6IcO1176Nfzdso9q70p16/f31vHbt+sYOIvtS3pPV/VeKu0rkL405T0H/0vBPoH7dspDeRMylvwqH9/w+At0baUHfo05ebSdMqNs6CcuZ5PuXmwL6UBvIrSGLtxv0BptD9HuUxxD+XmVH/j7EYJlc0pO3ImZYN3Nwn6Z+kuhJ/Xq+/K3nz6b/e6t4mb1nG6UO0HcDddt22S8omAx3rbanFv3C0Z7KPte9NtWte/OwEl5US1ojeP7YC3RcRbKCedoNwQ68J7G+AltXwxg4N1E8q27A5+gHMZBOnSUet2aH0+v1f3zSi9iGmUg/F5tfz7vem6x+1689ukPk6jNPDuYH20N00AX+nV7UAG++alDAK3Hy7dyXpTyol6BoMDezPKW+Uj6/PNKW/7qcPv6M1/01qPGZSA3rqOtzvl4I+6Dt3N0WBwoC7sbYfu2ndnawZta0ZvHW6ry6Q+9tvxL9fHg3hmGASDdhw8M3gfYdDz7ObZ92IG7bD7JM70Ov9davmNDAKu36vuLn916/EIg2C6tle3oLS97tJAF4y7ULb9trWsu/w1nXKpoAvb6+rz6ZRwfbjO++A6v217y01K25/ZW68VtW77UI6prt1/C/jd+nxLSltaE/8JvCkiNo+IrSi5smrr4nLEqLIVlLNm17vtQnWEQQ/iwwzexox+a3I95cDtPu4z+q3jMspOWwmcRDkAumuGP6ScSR/rTddddhh9Y65769rdOFlRpx19E2X028B+2WRufIyefry3+936dW/3+uMsnaB8JSWk+jceFo4z76UM3sLdNc7yk9KY75hg3VZSelbj3djKUeONvkGSjH/T6poJ5jXRDaHvMvjY32S3eTK4TLC0bqvR8390nGlW9v7Ge/vcjdPf1kvqtn2q93q8enbz6t5trGDwLqD/1/Xsb+7t/+SZN7f67WP0ZaKJtuONDC6/dOsx0fqNN87Kuj+7Xnv/pmN3jPX3U3dMvp7y7nf0vunm29287a9Hv14f6Q27l2e2g/Ha3Ajwd73t0W+DD1Cu445QwngppX3fSsme7sbcD4E9KCfouye4HPG+Xu7dDOzeG/YjyqWiC4HjV5mjaxPCU/kP2Ko+bk8J150mOd1ewHfWcJlbMvgq+FuBS1anvpSz8gtrfQ8GbljP2+xM4LhJjDeNcpLdYwh1+Cz10zbjDDuG1fh501HT7k79bPna7OO1XLdZlI9vdq/vBnZYh/OfDmxen/8M5Xryputgvu8D/qp3TAXwT8AfrsY8umlnUN7JHLqO1nmr3vNTgNNbb7veum5JuV+2z6rGnzI/4DMEl0XENpS3XH+VmWP/HcAoEXEC5RrnyWu4zF8CzoyI7m3gO1dj2ssoAfwSypn4VOD4NazHaouI6ym9u/c+y3h7Uup6cWbesT7qti6tg328pib+514AAAI8SURBVMs9hfKlg7cNcTFbAtdExCaUoPz9zFz6LNOsUkRcTAml/YDjI+JoyjH1fcr14Mk6NSL+J+WSw5WUG+frwsER8SeUcL+HcqJeE+ty251dj5PNgXMz83urGtkf8JGkhvztCElqyBCWpIYMYUlqyBDWBi0iXh8R+z77mFIbhrCeM0b92thkvZ7y5Z5hL0daI346QlNKRBxF+Vxq9+WC7qurr6R8G+nj9W8m5QP/x2fm7RHxJsqv521K+XLK2yjfeLyOwddZ/4DyYf9PUz6EPwIcm5n/FRGf7S8nM9+zPtZXMoQ1ZUTEzwMXA/tm5kMRsR3lB1B2AGZn5oqIuBo4ITPviIhXA3+TmftFxLbAY5mZEfE7wM9l5nsj4lTKNzs/UpfxFeCCzDw3It4JvDkzD6kh/JPlrO9118bLt12aSvYDzs/MhwAy85HyvRfOrwG8FeXSwvm1HAbf/d8V+GJE7EzpDf94gmW8FjisPv9nytdbO+cbwFrfDGE9Fyysj9Movd29xxnnY8BHM/PSiHg95RuHa7ocab3xxpymkq8Bb4mI7QHq5YifyMwngB/XX4aj/ougvergF1B+JAbg6N5kT/LMf4n1TcrvekC5bvyNdboG0moyhDVlZOYtlH/++PWI+AHlevBobwOOq8NvofyTVyg93/Prb2A81Bv/K8ChEXFDRLyOcnPu2Ii4kfIfLd49lJWRJskbc5LUkD1hSWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWro/wPFEu2RXBOttAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, there are only two classes that have high counts: Marvel Comics and DC Comics. There are many other creators but their counts are very low. Hence, for my project, I decided to only consider the top two classes, as the count of the rest is low enough to be left out.  "
      ],
      "metadata": {
        "id": "bigBFLggrz60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# only keeping the rows in which the creator is Marvel Comics or DC Comics\n",
        "indexAge = df[ (df['creator'] != 'Marvel Comics') & (df['creator'] != 'DC Comics') ].index\n",
        "df.drop(indexAge , inplace=True)\n",
        "df.head()\n",
        "\n",
        "# plotting a graph that shows the distribution of the new target classes.\n",
        "sb.catplot(x='creator', kind='count', data=df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "d_VUfbC7-8N1",
        "outputId": "757b2655-3409-424f-bd78-6a092667a97a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7fe7d0ce6520>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = df[\"history_text\"]\n",
        "print(features.head())\n",
        "target = df[\"creator\"]\n",
        "print(target.head())\n",
        "\n",
        "target = target.astype({\"creator\":'category'})\n",
        "\n"
      ],
      "metadata": {
        "id": "WbfsxS2GAnj2",
        "outputId": "792add69-dd1f-46ab-9afd-1fd9ec3a5a3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    Delroy Garrett, Jr. grew up to become a track ...\n",
            "1    He was one of the many prisoners of Indian Hil...\n",
            "2     Richard \"Rick\" Jones was orphaned at a young ...\n",
            "3    Aa is one of the more passive members of the P...\n",
            "4    Aaron Cash is the head of security at Arkham A...\n",
            "Name: history_text, dtype: object\n",
            "0    Marvel Comics\n",
            "1        DC Comics\n",
            "2    Marvel Comics\n",
            "3        DC Comics\n",
            "4        DC Comics\n",
            "Name: creator, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting into Train and Test sets\n"
      ],
      "metadata": {
        "id": "0twUp5A8slB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "lBSyrRNmAok6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, train_size=0.8, random_state=1234)"
      ],
      "metadata": {
        "id": "xyOi5dcuFPt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizing and Encoding Data"
      ],
      "metadata": {
        "id": "-yNccx3T4vZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set up X and Y\n",
        "num_labels = 2\n",
        "vocab_size = 25000\n",
        "batch_size = 100\n",
        "\n",
        "# fit the tokenizer on the training data\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "x_train_tok = tokenizer.texts_to_matrix(X_train, mode='tfidf')\n",
        "x_test_tok = tokenizer.texts_to_matrix(X_test, mode='tfidf')\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(y_train)\n",
        "y_train_tok = encoder.transform(y_train)\n",
        "y_test_tok = encoder.transform(y_test)\n",
        "\n",
        "# check shape\n",
        "print(\"train shapes:\", x_train_tok.shape, y_train_tok.shape)\n",
        "print(\"test shapes:\", x_test_tok.shape, y_test_tok.shape)\n",
        "print(\"test first five labels:\", y_test_tok[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awe_x03EFSri",
        "outputId": "7c5acf4d-6212-41a0-f77b-44d47319290f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train shapes: (797, 25000) (797,)\n",
            "test shapes: (200, 25000) (200,)\n",
            "test first five labels: [0 0 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sequential Models\n",
        "\n",
        "I tried two sequential models with different topologies. "
      ],
      "metadata": {
        "id": "m1v1MxTcs46s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 25000\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(32, input_dim=vocab_size, kernel_initializer='normal', activation='relu'))\n",
        "model.add(layers.Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
        " \n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "history = model.fit(x_train_tok, y_train_tok,\n",
        "                    epochs=50,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2ULIpqAEW1g",
        "outputId": "a7e95587-b2c5-4e85-c0b7-4a6b561a67fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "23/23 [==============================] - 1s 18ms/step - loss: 0.5971 - accuracy: 0.6681 - val_loss: 0.4415 - val_accuracy: 0.7875\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.2867 - accuracy: 0.9456 - val_loss: 0.3027 - val_accuracy: 0.9000\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.1621 - accuracy: 0.9861 - val_loss: 0.2174 - val_accuracy: 0.9375\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0962 - accuracy: 0.9944 - val_loss: 0.1762 - val_accuracy: 0.9500\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0630 - accuracy: 0.9958 - val_loss: 0.1549 - val_accuracy: 0.9500\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0449 - accuracy: 0.9986 - val_loss: 0.1419 - val_accuracy: 0.9500\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.1348 - val_accuracy: 0.9500\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 0.1304 - val_accuracy: 0.9500\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.1279 - val_accuracy: 0.9500\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.1260 - val_accuracy: 0.9500\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.1250 - val_accuracy: 0.9500\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.1248 - val_accuracy: 0.9625\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.1247 - val_accuracy: 0.9625\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.1245 - val_accuracy: 0.9625\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.1249 - val_accuracy: 0.9625\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1250 - val_accuracy: 0.9625\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.1257 - val_accuracy: 0.9625\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.1258 - val_accuracy: 0.9625\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.1264 - val_accuracy: 0.9625\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.1272 - val_accuracy: 0.9625\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1276 - val_accuracy: 0.9625\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1285 - val_accuracy: 0.9625\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1289 - val_accuracy: 0.9625\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1297 - val_accuracy: 0.9625\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1302 - val_accuracy: 0.9625\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1308 - val_accuracy: 0.9625\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1316 - val_accuracy: 0.9625\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1323 - val_accuracy: 0.9625\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1330 - val_accuracy: 0.9625\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1336 - val_accuracy: 0.9625\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1341 - val_accuracy: 0.9625\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1349 - val_accuracy: 0.9625\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1353 - val_accuracy: 0.9625\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1360 - val_accuracy: 0.9625\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1367 - val_accuracy: 0.9625\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1374 - val_accuracy: 0.9625\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1377 - val_accuracy: 0.9625\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1386 - val_accuracy: 0.9625\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1394 - val_accuracy: 0.9625\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1400 - val_accuracy: 0.9625\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1405 - val_accuracy: 0.9625\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1411 - val_accuracy: 0.9625\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1417 - val_accuracy: 0.9625\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1423 - val_accuracy: 0.9625\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 9.8326e-04 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 0.9625\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 9.4084e-04 - accuracy: 1.0000 - val_loss: 0.1437 - val_accuracy: 0.9625\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 8.8929e-04 - accuracy: 1.0000 - val_loss: 0.1442 - val_accuracy: 0.9625\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 8.4761e-04 - accuracy: 1.0000 - val_loss: 0.1448 - val_accuracy: 0.9625\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 8.1185e-04 - accuracy: 1.0000 - val_loss: 0.1452 - val_accuracy: 0.9625\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 7.7479e-04 - accuracy: 1.0000 - val_loss: 0.1457 - val_accuracy: 0.9625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accuracy of first sequential model"
      ],
      "metadata": {
        "id": "yBKRzPGMtI74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "pred = model.predict(x_test_tok)\n",
        "pred_labels = [1 if p>0.5 else 0 for p in pred]\n",
        "Seq1accuracy = []\n",
        "Seq1accuracy += [accuracy_score(y_test_tok, pred_labels)]\n",
        "Seq1accuracy += [precision_score(y_test_tok, pred_labels)]\n",
        "Seq1accuracy += [recall_score(y_test_tok, pred_labels)]\n",
        "Seq1accuracy += [f1_score(y_test_tok, pred_labels)]\n",
        "print('accuracy score: ', Seq1accuracy[0])\n",
        "print('precision score: ', Seq1accuracy[1])\n",
        "print('recall score: ', Seq1accuracy[2])\n",
        "print('f1 score: ', Seq1accuracy[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eq7rYGc1IJdL",
        "outputId": "6ca06715-0a26-42f7-8927-1b1d9f639b3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 4ms/step\n",
            "accuracy score:  0.905\n",
            "precision score:  0.9210526315789473\n",
            "recall score:  0.9130434782608695\n",
            "f1 score:  0.9170305676855894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Second Sequential Model"
      ],
      "metadata": {
        "id": "fDQca6lstO2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = models.Sequential()\n",
        "model2.add(layers.Dense(16, activation='relu', input_shape=(25000,)))\n",
        "model2.add(layers.Dense(16, activation='relu'))\n",
        "model2.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "vGgSdHhlIh4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "blq2dz9lI3Wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history2 = model2.fit(x_train_tok,\n",
        "                    y_train_tok,\n",
        "                    epochs=20,\n",
        "                    \n",
        "                    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnGr5I75I6k9",
        "outputId": "63899915-b1e8-4174-8088-a9e05e17b5cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 1.2942e-04 - accuracy: 1.0000\n",
            "Epoch 2/20\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 9.9926e-05 - accuracy: 1.0000\n",
            "Epoch 3/20\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 7.6616e-05 - accuracy: 1.0000\n",
            "Epoch 4/20\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 5.7728e-05 - accuracy: 1.0000\n",
            "Epoch 5/20\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 4.4017e-05 - accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 3.5131e-05 - accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 2.8583e-05 - accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 2.2764e-05 - accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 1.8326e-05 - accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 1.4416e-05 - accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 1.1967e-05 - accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 9.7787e-06 - accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7.9867e-06 - accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 6.5875e-06 - accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 5.4610e-06 - accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4.4627e-06 - accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 3.6697e-06 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 3.0275e-06 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 2.4542e-06 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 2.0222e-06 - accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accuracy of second sequential model"
      ],
      "metadata": {
        "id": "-n56vALxtSyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred2 = model2.predict(x_test_tok)\n",
        "pred_labels2 = [1 if p>0.5 else 0 for p in pred2]\n",
        "Seq2accuracy = []\n",
        "Seq2accuracy += [accuracy_score(y_test_tok, pred_labels2)]\n",
        "Seq2accuracy += [precision_score(y_test_tok, pred_labels2)]\n",
        "Seq2accuracy += [recall_score(y_test_tok, pred_labels2)]\n",
        "Seq2accuracy += [f1_score(y_test_tok, pred_labels2)]\n",
        "print('accuracy score: ', Seq2accuracy[0])\n",
        "print('precision score: ', Seq2accuracy[1])\n",
        "print('recall score: ', Seq2accuracy[2])\n",
        "print('f1 score: ', Seq2accuracy[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tbMfR-zJLR7",
        "outputId": "eea1a58e-4e32-4200-89bd-f302e1a06ad7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 3ms/step\n",
            "accuracy score:  0.885\n",
            "precision score:  0.896551724137931\n",
            "recall score:  0.9043478260869565\n",
            "f1 score:  0.9004329004329004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN Model"
      ],
      "metadata": {
        "id": "Bpe2j014tbEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = 25000\n",
        "maxlen = 25000\n",
        "modelCNN = models.Sequential()\n",
        "modelCNN.add(layers.Embedding(max_features, 128, input_length=maxlen)) \n",
        "modelCNN.add(layers.Conv1D(32, 7, activation='relu')) \n",
        "modelCNN.add(layers.MaxPooling1D(5)) \n",
        "modelCNN.add(layers.Conv1D(32, 7, activation='relu')) \n",
        "modelCNN.add(layers.GlobalMaxPooling1D())\n",
        "modelCNN.add(layers.Dense(1))\n"
      ],
      "metadata": {
        "id": "x5LlpZvOJXZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelCNN.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),  # set learning rate\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GehcHFnPKn59",
        "outputId": "2875e766-1db4-4d95-d2b6-a0db51209fed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history3 = modelCNN.fit(x_train_tok,\n",
        "                    y_train_tok,\n",
        "                    epochs=10,\n",
        "                    verbose = 1,\n",
        "                    validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKdnqTUKKs-k",
        "outputId": "8f798ab5-7438-4616-a5ad-8de76094078d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "23/23 [==============================] - 158s 7s/step - loss: 1.0339 - accuracy: 0.4142 - val_loss: 0.7780 - val_accuracy: 0.4000\n",
            "Epoch 2/10\n",
            "23/23 [==============================] - 156s 7s/step - loss: 0.7113 - accuracy: 0.5091 - val_loss: 0.6652 - val_accuracy: 0.5875\n",
            "Epoch 3/10\n",
            "23/23 [==============================] - 127s 5s/step - loss: 0.6653 - accuracy: 0.5983 - val_loss: 0.6575 - val_accuracy: 0.6500\n",
            "Epoch 4/10\n",
            "23/23 [==============================] - 123s 5s/step - loss: 0.6618 - accuracy: 0.6067 - val_loss: 0.6568 - val_accuracy: 0.6500\n",
            "Epoch 5/10\n",
            "23/23 [==============================] - 120s 5s/step - loss: 0.6604 - accuracy: 0.6025 - val_loss: 0.6590 - val_accuracy: 0.6375\n",
            "Epoch 6/10\n",
            "23/23 [==============================] - 122s 5s/step - loss: 0.6598 - accuracy: 0.6011 - val_loss: 0.6561 - val_accuracy: 0.6500\n",
            "Epoch 7/10\n",
            "23/23 [==============================] - 123s 5s/step - loss: 0.6574 - accuracy: 0.6067 - val_loss: 0.6577 - val_accuracy: 0.6500\n",
            "Epoch 8/10\n",
            "23/23 [==============================] - 121s 5s/step - loss: 0.6555 - accuracy: 0.6109 - val_loss: 0.6592 - val_accuracy: 0.6000\n",
            "Epoch 9/10\n",
            "23/23 [==============================] - 122s 5s/step - loss: 0.6534 - accuracy: 0.6081 - val_loss: 0.6565 - val_accuracy: 0.6500\n",
            "Epoch 10/10\n",
            "23/23 [==============================] - 123s 5s/step - loss: 0.6515 - accuracy: 0.6109 - val_loss: 0.6598 - val_accuracy: 0.6500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accuracy of CNN Model"
      ],
      "metadata": {
        "id": "e2h0YxKXthZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predCNN = modelCNN.predict(x_test_tok)\n",
        "pred_labelsCNN = [1 if p>0.5 else 0 for p in predCNN]\n",
        "CNNaccuracy = []\n",
        "CNNaccuracy += [accuracy_score(y_test_tok, pred_labelsCNN)]\n",
        "CNNaccuracy += [precision_score(y_test_tok, pred_labelsCNN)]\n",
        "CNNaccuracy += [recall_score(y_test_tok, pred_labelsCNN)]\n",
        "CNNaccuracy += [f1_score(y_test_tok, pred_labelsCNN)]\n",
        "print('accuracy score: ', CNNaccuracy[0])\n",
        "print('precision score: ', CNNaccuracy[1])\n",
        "print('recall score: ', CNNaccuracy[2])\n",
        "print('f1 score: ', CNNaccuracy[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfGm8HcFlGfF",
        "outputId": "ab4ff2b2-e814-4a78-f906-39ed0fa686a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 7s 972ms/step\n",
            "accuracy score:  0.595\n",
            "precision score:  0.5934065934065934\n",
            "recall score:  0.9391304347826087\n",
            "f1 score:  0.7272727272727273\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding Approach"
      ],
      "metadata": {
        "id": "XnNn8taclVcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# set up the Embedding layer in a Sequential model\n",
        "\n",
        "modelEmb = models.Sequential()\n",
        "modelEmb.add(layers.Embedding(max_features, 8, input_length=maxlen))\n",
        "modelEmb.add(layers.Flatten())\n",
        "modelEmb.add(layers.Dense(16, activation='relu', input_shape=(25000,)))\n",
        "modelEmb.add(layers.Dense(16, activation='relu'))\n",
        "modelEmb.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "modelEmb.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "modelEmb.summary()\n",
        "\n",
        "historyEmb = modelEmb.fit(x_train_tok, y_train_tok, epochs=10, validation_split=0.1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkVGfS7UlU5j",
        "outputId": "859237b4-373f-4b68-e5cd-bbf979a2c320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_7 (Embedding)     (None, 25000, 8)          200000    \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 200000)            0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 16)                3200016   \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 16)                272       \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,400,305\n",
            "Trainable params: 3,400,305\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "23/23 [==============================] - 4s 135ms/step - loss: 0.7162 - acc: 0.5746 - val_loss: 0.6761 - val_acc: 0.6000\n",
            "Epoch 2/10\n",
            "23/23 [==============================] - 3s 112ms/step - loss: 0.6817 - acc: 0.5858 - val_loss: 0.6769 - val_acc: 0.6000\n",
            "Epoch 3/10\n",
            "23/23 [==============================] - 4s 161ms/step - loss: 0.6920 - acc: 0.5858 - val_loss: 0.6723 - val_acc: 0.6000\n",
            "Epoch 4/10\n",
            "23/23 [==============================] - 3s 136ms/step - loss: 0.6793 - acc: 0.5858 - val_loss: 0.6724 - val_acc: 0.6000\n",
            "Epoch 5/10\n",
            "23/23 [==============================] - 3s 113ms/step - loss: 0.6781 - acc: 0.5858 - val_loss: 0.6756 - val_acc: 0.6000\n",
            "Epoch 6/10\n",
            "23/23 [==============================] - 4s 163ms/step - loss: 0.6763 - acc: 0.5858 - val_loss: 0.6680 - val_acc: 0.6000\n",
            "Epoch 7/10\n",
            "23/23 [==============================] - 5s 216ms/step - loss: 0.6711 - acc: 0.5872 - val_loss: 0.5982 - val_acc: 0.7000\n",
            "Epoch 8/10\n",
            "23/23 [==============================] - 4s 152ms/step - loss: 0.6249 - acc: 0.7155 - val_loss: 0.5969 - val_acc: 0.6125\n",
            "Epoch 9/10\n",
            "23/23 [==============================] - 5s 231ms/step - loss: 0.4766 - acc: 0.7768 - val_loss: 0.4498 - val_acc: 0.7875\n",
            "Epoch 10/10\n",
            "23/23 [==============================] - 3s 146ms/step - loss: 0.3651 - acc: 0.8884 - val_loss: 0.3601 - val_acc: 0.8625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accuracy of Embedding Approach"
      ],
      "metadata": {
        "id": "aonY_DH7tpCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predEmb = modelEmb.predict(x_test_tok)\n",
        "pred_labelsEmb = [1 if p>0.5 else 0 for p in predEmb]\n",
        "Embaccuracy = []\n",
        "Embaccuracy += [accuracy_score(y_test_tok, pred_labelsEmb)]\n",
        "Embaccuracy += [precision_score(y_test_tok, pred_labelsEmb)]\n",
        "Embaccuracy += [recall_score(y_test_tok, pred_labelsEmb)]\n",
        "Embaccuracy += [f1_score(y_test_tok, pred_labelsEmb)]\n",
        "print('accuracy score: ', Embaccuracy[0])\n",
        "print('precision score: ', Embaccuracy[1])\n",
        "print('recall score: ', Embaccuracy[2])\n",
        "print('f1 score: ', Embaccuracy[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1qNjhMUnPCF",
        "outputId": "ed7121b1-a472-4187-ad99-cd0b7786e0a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 24ms/step\n",
            "accuracy score:  0.875\n",
            "precision score:  0.8260869565217391\n",
            "recall score:  0.991304347826087\n",
            "f1 score:  0.901185770750988\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Another Embedding Approach"
      ],
      "metadata": {
        "id": "ZZIqLYZIovgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "modelEmb2 = models.Sequential()\n",
        "modelEmb2.add(layers.Embedding(max_features, 8, input_length=maxlen))\n",
        "modelEmb2.add(layers.Flatten())\n",
        "modelEmb2.add(layers.Dense(32, input_dim=vocab_size, kernel_initializer='normal', activation='relu'))\n",
        "modelEmb2.add(layers.Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
        "\n",
        "modelEmb2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "modelEmb2.summary()\n",
        "\n",
        "historyEmb2 = modelEmb2.fit(x_train_tok, y_train_tok, verbose=1,epochs=20, validation_split=0.1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cm9iJHpOoOVC",
        "outputId": "009f85df-02c2-458c-c39d-f90e2d451ffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_10 (Embedding)    (None, 25000, 8)          200000    \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 200000)            0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 32)                6400032   \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,600,065\n",
            "Trainable params: 6,600,065\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "23/23 [==============================] - 4s 112ms/step - loss: 0.6922 - accuracy: 0.5537 - val_loss: 0.6764 - val_accuracy: 0.6000\n",
            "Epoch 2/20\n",
            "23/23 [==============================] - 2s 104ms/step - loss: 0.6805 - accuracy: 0.5858 - val_loss: 0.6725 - val_accuracy: 0.6000\n",
            "Epoch 3/20\n",
            "23/23 [==============================] - 4s 160ms/step - loss: 0.6768 - accuracy: 0.5858 - val_loss: 0.6694 - val_accuracy: 0.6000\n",
            "Epoch 4/20\n",
            "23/23 [==============================] - 2s 105ms/step - loss: 0.6712 - accuracy: 0.5858 - val_loss: 0.6635 - val_accuracy: 0.6000\n",
            "Epoch 5/20\n",
            "23/23 [==============================] - 2s 104ms/step - loss: 0.6583 - accuracy: 0.5858 - val_loss: 0.6447 - val_accuracy: 0.6000\n",
            "Epoch 6/20\n",
            "23/23 [==============================] - 2s 106ms/step - loss: 0.6270 - accuracy: 0.6248 - val_loss: 0.6253 - val_accuracy: 0.7500\n",
            "Epoch 7/20\n",
            "23/23 [==============================] - 2s 105ms/step - loss: 0.5698 - accuracy: 0.7183 - val_loss: 0.5657 - val_accuracy: 0.6125\n",
            "Epoch 8/20\n",
            "23/23 [==============================] - 2s 103ms/step - loss: 0.5167 - accuracy: 0.7238 - val_loss: 0.5207 - val_accuracy: 0.6375\n",
            "Epoch 9/20\n",
            "23/23 [==============================] - 2s 104ms/step - loss: 0.4213 - accuracy: 0.8954 - val_loss: 0.4397 - val_accuracy: 0.9125\n",
            "Epoch 10/20\n",
            "23/23 [==============================] - 2s 105ms/step - loss: 0.3363 - accuracy: 0.9554 - val_loss: 0.3845 - val_accuracy: 0.9125\n",
            "Epoch 11/20\n",
            "23/23 [==============================] - 2s 105ms/step - loss: 0.2783 - accuracy: 0.9386 - val_loss: 0.3647 - val_accuracy: 0.8750\n",
            "Epoch 12/20\n",
            "23/23 [==============================] - 2s 104ms/step - loss: 0.2424 - accuracy: 0.9261 - val_loss: 0.3511 - val_accuracy: 0.9125\n",
            "Epoch 13/20\n",
            "23/23 [==============================] - 2s 104ms/step - loss: 0.1910 - accuracy: 0.9777 - val_loss: 0.3186 - val_accuracy: 0.9125\n",
            "Epoch 14/20\n",
            "23/23 [==============================] - 2s 103ms/step - loss: 0.1541 - accuracy: 0.9777 - val_loss: 0.3337 - val_accuracy: 0.8625\n",
            "Epoch 15/20\n",
            "23/23 [==============================] - 2s 105ms/step - loss: 0.1237 - accuracy: 0.9902 - val_loss: 0.2948 - val_accuracy: 0.9250\n",
            "Epoch 16/20\n",
            "23/23 [==============================] - 2s 107ms/step - loss: 0.1000 - accuracy: 0.9861 - val_loss: 0.2974 - val_accuracy: 0.9250\n",
            "Epoch 17/20\n",
            "23/23 [==============================] - 2s 104ms/step - loss: 0.0807 - accuracy: 0.9902 - val_loss: 0.3636 - val_accuracy: 0.8250\n",
            "Epoch 18/20\n",
            "23/23 [==============================] - 2s 104ms/step - loss: 0.0708 - accuracy: 0.9930 - val_loss: 0.3884 - val_accuracy: 0.8375\n",
            "Epoch 19/20\n",
            "23/23 [==============================] - 2s 106ms/step - loss: 0.0547 - accuracy: 0.9944 - val_loss: 0.2503 - val_accuracy: 0.9250\n",
            "Epoch 20/20\n",
            "23/23 [==============================] - 3s 140ms/step - loss: 0.0441 - accuracy: 0.9944 - val_loss: 0.2436 - val_accuracy: 0.9375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accuracy of Second Embedding Approach"
      ],
      "metadata": {
        "id": "AQlixs1ytu9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predEmb2 = modelEmb2.predict(x_test_tok)\n",
        "pred_labelsEmb2 = [1 if p>0.5 else 0 for p in predEmb2]\n",
        "Emb2accuracy = []\n",
        "Emb2accuracy += [accuracy_score(y_test_tok, pred_labelsEmb2)]\n",
        "Emb2accuracy += [precision_score(y_test_tok, pred_labelsEmb2)]\n",
        "Emb2accuracy += [recall_score(y_test_tok, pred_labelsEmb2)]\n",
        "Emb2accuracy += [f1_score(y_test_tok, pred_labelsEmb2)]\n",
        "print('accuracy score: ', Emb2accuracy[0])\n",
        "print('precision score: ', Emb2accuracy[1])\n",
        "print('recall score: ', Emb2accuracy[2])\n",
        "print('f1 score: ', Emb2accuracy[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r25cT00ypcEn",
        "outputId": "fd60d352-b105-49fd-a9df-a2d2fbde592c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 39ms/step\n",
            "accuracy score:  0.9\n",
            "precision score:  0.8991596638655462\n",
            "recall score:  0.9304347826086956\n",
            "f1 score:  0.9145299145299145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accuracy Table"
      ],
      "metadata": {
        "id": "pVaZlGkot2y0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d = {\n",
        "    'Sequential 1': Seq1accuracy, 'Sequential 2': Seq2accuracy,\n",
        "    'CNN': CNNaccuracy, 'Embedding 1': Embaccuracy, 'Embedding 2': Emb2accuracy,\n",
        "    }\n",
        "\n",
        "print(\"Total Accuracies:\\n\")\n",
        "tot_acc = pd.DataFrame(data=d)\n",
        "tot_acc.insert(0, \"Metrics\", [\"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
        "print(tot_acc.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0X0Tjoe9t6Xt",
        "outputId": "169fbc6e-b657-4223-ed28-af1f4700d4d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Accuracies:\n",
            "\n",
            "  Metrics  Sequential 1  Sequential 2      CNN  Embedding 1  Embedding 2\n",
            " Accuracy      0.905000      0.885000 0.595000     0.875000     0.900000\n",
            "Precision      0.921053      0.896552 0.593407     0.826087     0.899160\n",
            "   Recall      0.913043      0.904348 0.939130     0.991304     0.930435\n",
            "       F1      0.917031      0.900433 0.727273     0.901186     0.914530\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Analysis\n",
        "\n",
        "As can be seen from the above table, the very first sequential model performed the best. It had an accuracy 90.5% which was higher than all of other model's accuracies. The CNN approach ended up performing the worst and it also took a long time to train. It took about 20 minutes whereas the other models took barely a minute to train. \n",
        "\n",
        "Initially, I was getting even worse results with the CNN model. I was getting accuracies of about 40%. After changing the topology a few times, I was able to get it to 59% which still isn't that good. \n",
        "\n",
        "I did 2 sequential models because I wanted to try different topologies and see how they performed. I also did 2 models with embedding approaches for the same reason. In the second embedding approach, I kept everything the same as the the first sequential model, and just added an embedding layer. That gave me very good results as I was able to get an accuracy of 90%.\n",
        "\n",
        "All in all, it seems that for my dataset, using a simple sequential model seemed to do the trick. I achieved the best metrics through it and it was very efficient time-wise as well.\n"
      ],
      "metadata": {
        "id": "nVYOD0tTwfNx"
      }
    }
  ]
}